{"metadata":{"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"},"colab":{"collapsed_sections":["C7KRIcKfz9Cq","2v2H3PTjBwEM","Hpky3tJ_Btzd","vdDAkBcec1iv","zMHQml9R6p-F","giywpqTIdWMq","RRvdm8uMdrcO","F2dmCIuzKFUe","NPSDrbKEBUNc","mbqQLlHJektP","H7hRZwRIektP","DpLToLiDuDQM"],"provenance":[],"toc_visible":true},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":10571937,"sourceType":"datasetVersion","datasetId":6528302}],"dockerImageVersionId":30839,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"source":"<a href=\"https://www.kaggle.com/code/yoansadel/group3?scriptVersionId=218801214\" target=\"_blank\"><img align=\"left\" alt=\"Kaggle\" title=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"></a>","metadata":{},"cell_type":"markdown"},{"cell_type":"markdown","source":">Many diseases such as cancer, tumors, and pneumonia are detected using computer-aided diagnosis with the help of AI models.\nThis project focuses on disease prediction using a Brain Tumors Images dataset.\nIt consists of two types of labbeled categories:\n>1. **Meningioma (Menin)**\n>2. **Glioma**","metadata":{"id":"dh9U11PDgiWd"}},{"cell_type":"markdown","source":"# Importing Libraries and Defining Functions","metadata":{"id":"NIyOoq39410i"}},{"cell_type":"code","source":"!pip install split-folders","metadata":{"executionInfo":{"elapsed":4937,"status":"ok","timestamp":1737831049295,"user":{"displayName":"Yoans Adel","userId":"04177296913070558532"},"user_tz":-120},"id":"JvPp6SuJCfW3","outputId":"4f44d97c-93e2-4de6-8417-f2c23a1fe674"},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport splitfolders\nfrom imutils import paths\nimport shutil\nimport random\nimport cv2\nimport tensorflow\nfrom tensorflow import keras\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nimport torch\nfrom torch.utils.data import DataLoader, TensorDataset\nimport os\nimport splitfolders\nimport logging\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torchvision import models\nfrom torch.utils.data import DataLoader, TensorDataset\nfrom torchsummary import summary\nfrom sklearn.metrics import confusion_matrix\nimport seaborn as sns\nfrom sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score","metadata":{"id":"imTmQNe-aumZ","executionInfo":{"status":"ok","timestamp":1737862635128,"user_tz":-120,"elapsed":273,"user":{"displayName":"Yoans Adel","userId":"04177296913070558532"}}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#copy data from input to output folder and overwrite exiting files\ndef copy_data(input_folder, output_folder, overwrite=False):\n    \"\"\"\n    Args:\n        input_folder (str): The path to the input folder.\n        output_folder (str): The path to the output folder.\n        overwrite (bool, optional): Whether to overwrite existing files. i set it False by defalt.\n    \"\"\"\n    logging.basicConfig(filename='copy_data.log', level=logging.INFO)\n\n    os.makedirs(output_folder, exist_ok=True)\n\n    for filename in os.listdir(input_folder):\n        source_path = os.path.join(input_folder, filename)\n        destination_path = os.path.join(output_folder, filename)\n\n        if os.path.isfile(source_path):\n            if os.path.exists(destination_path) and not overwrite:\n                logging.warning(f\"Skipping existing file: {destination_path}\")\n                continue\n            try:\n                shutil.copy2(source_path, destination_path)\n            except Exception as e:\n                logging.error(f\"Error copying file: {source_path} - {e}\")\n        elif os.path.isdir(source_path):\n            try:\n                shutil.copytree(source_path, destination_path, dirs_exist_ok=True)\n            except Exception as e:\n                logging.error(f\"Error copying directory: {source_path} - {e}\")","metadata":{"id":"qJgG54NACo2v","executionInfo":{"status":"ok","timestamp":1737835824845,"user_tz":-120,"elapsed":243,"user":{"displayName":"Yoans Adel","userId":"04177296913070558532"}}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#Extracts class names and their counts from a list of image paths.\ndef extract_classes_and_counts(imgPaths):\n  \"\"\"\n  Args:\n    imgPaths: A list of image paths.\n  Returns:\n  tuple: containing A list of class names and dictionary with class names and thier counts .\n  \"\"\"\n  classes = []\n  class_counts = {}\n\n  for imgPath in imgPaths:\n    className = imgPath.split('/')[-2]\n    if className not in classes:\n      classes.append(className)\n    class_counts[className] = class_counts.get(className, 0) + 1\n\n  return classes, class_counts","metadata":{"id":"42fsVkKzJuNt","executionInfo":{"status":"ok","timestamp":1737836923204,"user_tz":-120,"elapsed":247,"user":{"displayName":"Yoans Adel","userId":"04177296913070558532"}}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#Display random samples of images from generator\ndef show_images(generator, classes, num_images=25):\n    \"\"\"\n    Args:\n        generator: The data generator to use for loading images.\n        classes: A list of class names for labeling the images.\n        num_images (int, optional): Number of images to display (I made default edual 25 but you can change it).\n    \"\"\"\n\n    #Define a list contains all image paths and get them from the generator's directory\n    image_paths = list(paths.list_images(generator.directory))\n\n    #Get random images path depend on number you want to see\n    num_images = min(num_images, len(image_paths))\n    random_image_paths = random.sample(image_paths, num_images)\n\n    #Display images\n    plt.figure(figsize=(20, 20))\n    for i, image_path in enumerate(random_image_paths):\n        plt.subplot(5, 5, i + 1)  #Adjust subplot layout as needed\n\n        img = cv2.imread(image_path)\n        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)  #Convert images to RGB\n        img = cv2.resize(img, generator.target_size)\n        plt.imshow(img / 255.0)  # Rescale if needed\n\n        #Get class name from the file path\n        class_name = os.path.basename(os.path.dirname(image_path))\n        plt.title(class_name, color='blue', fontsize=12)\n        plt.axis('off')\n\n    plt.show()","metadata":{"id":"2iGH8ktoNxMi","executionInfo":{"status":"ok","timestamp":1737857326077,"user_tz":-120,"elapsed":6,"user":{"displayName":"Yoans Adel","userId":"04177296913070558532"}}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#Trains the model for one epoch and return accuracy and loss.\ndef train_epoch(model, train_loader, criterion, optimizer, device):\n    \"\"\"\n    Args:\n        model: your model to train.\n        train_loader: DataLoader for the training data.\n        criterion: loss function.\n        optimizer: optimizer to use.\n        device: The device to train on (e.g., 'cuda' or 'cpu').\n\n    Returns:\n        tuple: containing training loss and accuracy for the epoch.\n    \"\"\"\n    model.train()\n    running_loss = 0.0\n    correct_predictions = 0\n    total_samples = 0\n\n    for inputs, labels in train_loader:\n        inputs, labels = inputs.to(device), labels.to(device)\n\n        optimizer.zero_grad()\n        outputs = model(inputs)\n        loss = criterion(outputs, labels)\n        loss.backward()\n        optimizer.step()\n\n        running_loss += loss.item()\n        _, preds = torch.max(outputs, 1)\n        correct_predictions += (preds == labels).sum().item()\n        total_samples += labels.size(0)\n\n    train_loss = running_loss / len(train_loader)\n    train_accuracy = correct_predictions / total_samples * 100\n    return train_loss, train_accuracy","metadata":{"id":"zJjH_XpNgzV0","executionInfo":{"status":"ok","timestamp":1737835827600,"user_tz":-120,"elapsed":244,"user":{"displayName":"Yoans Adel","userId":"04177296913070558532"}}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#Evaluates the model's performance for one epoch on validation dataset and return val_accuracy and val_loss.\ndef validate_epoch(model, val_loader, criterion, device):\n    \"\"\"\n    Args:\n        model: your model to train.\n        val_loader: DataLoader for the validation data.\n        criterion: loss function.\n        device: The device to run the evaluation on (e.g., 'cuda' or 'cpu').\n    Returns:\n        tuple: containing validation loss and accuracy for the epoch.\n    \"\"\"\n    model.eval()\n    val_loss = 0.0\n    val_correct_predictions = 0\n    val_total_samples = 0\n\n    with torch.no_grad():\n        for inputs, labels in val_loader:\n            inputs, labels = inputs.to(device), labels.to(device)\n            outputs = model(inputs)\n            loss = criterion(outputs, labels)\n\n            val_loss += loss.item()\n            _, preds = torch.max(outputs, 1)\n            val_correct_predictions += (preds == labels).sum().item()\n            val_total_samples += labels.size(0)\n\n    val_loss = val_loss / len(val_loader)\n    val_accuracy = val_correct_predictions / val_total_samples * 100\n    return val_loss, val_accuracy","metadata":{"id":"Ma0UzN4LhAM5","executionInfo":{"status":"ok","timestamp":1737835829937,"user_tz":-120,"elapsed":339,"user":{"displayName":"Yoans Adel","userId":"04177296913070558532"}}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#Plots the training and validation loss and accuracy of the model.\n\ndef plot_training_history(train_losses, val_losses, train_accuracies, val_accuracies):\n    \"\"\"\n    Args:\n        train_losses (list): List of training losses.\n        val_losses (list): List of validation losses.\n        train_accuracies (list): List of training accuracies.\n        val_accuracies (list): List of validation accuracies.\n    \"\"\"\n\n    plt.figure(figsize=(12, 5))\n\n    # Training and validation loss\n    plt.subplot(1, 2, 1)\n    plt.plot(range(1, len(train_losses) + 1), train_losses, label=\"Train Loss\", color=\"red\", linestyle=\"-\", marker=\"o\")\n    plt.plot(range(1, len(val_losses) + 1), val_losses, label=\"Validation Loss\", color=\"green\", linestyle=\"-\", marker=\"o\")\n    plt.title(\"Train vs Validation Loss\", fontsize=14)\n    plt.xlabel(\"Epochs\", fontsize=12)\n    plt.ylabel(\"Loss\", fontsize=12)\n    plt.legend(fontsize=10)\n    plt.grid(True)\n\n    # Training and validation accuracy\n    plt.subplot(1, 2, 2)\n    plt.plot(range(1, len(train_accuracies) + 1), train_accuracies, label=\"Train Accuracy\", color=\"red\", linestyle=\"-\", marker=\"o\")\n    plt.plot(range(1, len(val_accuracies) + 1), val_accuracies, label=\"Validation Accuracy\", color=\"green\", linestyle=\"-\", marker=\"o\")\n    plt.title(\"Train vs Validation Accuracy\", fontsize=14)\n    plt.xlabel(\"Epochs\", fontsize=12)\n    plt.ylabel(\"Accuracy (%)\", fontsize=12)\n    plt.legend(fontsize=10)\n    plt.grid(True)\n\n    # Adjust layout and show the plot\n    plt.tight_layout()\n    plt.show()","metadata":{"id":"h1rrgPSrnxlt","executionInfo":{"status":"ok","timestamp":1737835955723,"user_tz":-120,"elapsed":240,"user":{"displayName":"Yoans Adel","userId":"04177296913070558532"}}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#Plots a confusion matrix\ndef plot_confusion_matrix(true_labels, predicted_labels, classes):\n    cm = confusion_matrix(true_labels, predicted_labels)\n    plt.figure(figsize=(8, 6))\n    sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=classes, yticklabels=classes)\n    plt.title(\"Confusion Matrix\")\n    plt.xlabel(\"Predicted Label\")\n    plt.ylabel(\"True Label\")\n    plt.show()","metadata":{"id":"uCbpmhEHrEKY","executionInfo":{"status":"ok","timestamp":1737862435065,"user_tz":-120,"elapsed":355,"user":{"displayName":"Yoans Adel","userId":"04177296913070558532"}}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#Displays random samples of images with their true and predicted labels.\ndef show_images_with_predictions(images, true_labels, predicted_labels, classes, num_images=25):\n    \"\"\"\n    Args:\n        images (list or NumPy array): images to display.\n        true_labels (list or NumPy array): true labels for the images.\n        predicted_labels (list or NumPy array): predicted labels for the images.\n        classes (list): List of class names.\n        num_images (int, optional): Number of images to display (I made default edual 25 but you can change it).\n    \"\"\"\n\n    num_images = min(num_images, len(images))\n    random_indices = random.sample(range(len(images)), num_images)\n\n    plt.figure(figsize=(20, 20))\n    for i, index in enumerate(random_indices):\n        plt.subplot(5, 5, i + 1)  # Adjust subplot layout as needed\n\n        img = images[index]\n        if isinstance(img, torch.Tensor):\n            img = img.cpu().numpy()  #Convert to NumPy if needed\n        img = img.astype(np.uint8)  #Ensure data type is uint8 for display\n\n        #Convert images to RGB\n        if img.shape[0] == 3:  #Channels-first format\n            img = img.transpose(1, 2, 0)\n        elif img.shape[-1] != 3:\n            img = cv2.cvtColor(img, cv2.COLOR_GRAY2RGB)\n\n        plt.imshow(img)\n\n        true_label = classes[true_labels[index]]\n        predicted_label = classes[predicted_labels[index]]\n\n        #Display title with true and predicted labels\n        title = f\"True: {true_label},\\nPredicted: {predicted_label}\"\n        title_color = \"blue\" if true_label == predicted_label else \"red\"  #Make incorrect predictions in red\n        plt.title(title, color=title_color, fontsize=12)\n\n        plt.axis('off')\n\n    plt.show()","metadata":{"id":"-0GRHlWkrFcZ","executionInfo":{"status":"ok","timestamp":1737862537018,"user_tz":-120,"elapsed":266,"user":{"displayName":"Yoans Adel","userId":"04177296913070558532"}}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Data Preprocessing and Visualization","metadata":{"id":"C7KRIcKfz9Cq"}},{"cell_type":"code","source":"#unmount\nfrom google.colab import drive\ndrive.flush_and_unmount()","metadata":{"id":"_yQVSYHD95M2","executionInfo":{"status":"ok","timestamp":1737831060762,"user_tz":-120,"elapsed":3,"user":{"displayName":"Yoans Adel","userId":"04177296913070558532"}},"outputId":"392d167e-af85-496e-d434-4f608b00ac8c"},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from google.colab import drive\ndrive.mount('/content/GoogleDrive')","metadata":{"executionInfo":{"elapsed":3609,"status":"ok","timestamp":1737862676806,"user":{"displayName":"Yoans Adel","userId":"04177296913070558532"},"user_tz":-120},"id":"ML7KsYs556qn","outputId":"d097237d-6dc5-4f6f-8a4a-5ea9a09a4d97"},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import warnings\nwarnings.filterwarnings(\"ignore\")","metadata":{"id":"5BKe03R_JwQB","executionInfo":{"status":"ok","timestamp":1737831112159,"user_tz":-120,"elapsed":2,"user":{"displayName":"Yoans Adel","userId":"04177296913070558532"}}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"input= '/content/GoogleDrive/MyDrive/Group3/test'\noutput= '/content/GoogleDrive/MyDrive/Group3/output'\ncopy_data(input, output)","metadata":{"id":"HsgL11sDf39f","executionInfo":{"status":"ok","timestamp":1737831589743,"user_tz":-120,"elapsed":477585,"user":{"displayName":"Yoans Adel","userId":"04177296913070558532"}}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"imgPaths = list(paths.list_images(output))\nif imgPaths:\n    print(imgPaths[0].split('/'))\nelse:\n    print(\"No images found.\")","metadata":{"executionInfo":{"elapsed":5,"status":"ok","timestamp":1737831589743,"user":{"displayName":"Yoans Adel","userId":"04177296913070558532"},"user_tz":-120},"id":"7nvObE0dEtJy","outputId":"f2a9e013-8bcd-412e-9de3-e171f0682807"},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#Dataset before balancing\nclasses, class_counts = extract_classes_and_counts(imgPaths)\n# Print the results\nprint(\"Classes:\", classes)\nprint(\"Class Counts:\", class_counts)","metadata":{"id":"gR_856IrJ5Ce","executionInfo":{"status":"ok","timestamp":1737862774946,"user_tz":-120,"elapsed":263,"user":{"displayName":"Yoans Adel","userId":"04177296913070558532"}},"outputId":"8dce281d-7a6d-4a46-dc4b-2f25c01db08c"},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#shuffle the images order\nrandom.shuffle(imgPaths)","metadata":{"id":"ZdLY3uGrf3Zx","executionInfo":{"status":"ok","timestamp":1737831589743,"user_tz":-120,"elapsed":5,"user":{"displayName":"Yoans Adel","userId":"04177296913070558532"}}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Data Augmentation","metadata":{"id":"2v2H3PTjBwEM"}},{"cell_type":"code","source":"# Data Augmentation for 'brain_menin' class\ndatagen = ImageDataGenerator(\n    rotation_range=20,\n    width_shift_range=0.2,\n    height_shift_range=0.2,\n    shear_range=0.2,\n    zoom_range=0.2,\n    horizontal_flip=True,\n    fill_mode='nearest'\n)\n\nmenin_dir = '/content/GoogleDrive/MyDrive/Group3/output/brain_menin'\n#menin_image_paths = list(paths.list_images(menin_dir))\naugmented_dir = '/content/augmen_brain_menin'\n\nos.makedirs(augmented_dir, exist_ok=True)\n\nbrain_glioma_count = class_counts['brain_glioma']\nbrain_menin_count = class_counts['brain_menin']\ntarget_count = brain_glioma_count\n#augment_count = max(0, target_count)\n\n# Augmentation\ni = 1\nfor img_path in paths.list_images(menin_dir):\n    img = cv2.imread(img_path)\n    if img is None:\n        print(f\"Error reading image: {img_path}\")\n        continue\n\n    img = img.reshape((1,) + img.shape)  # Reshape for ImageDataGenerator\n\n    for batch in datagen.flow(\n        img,\n        batch_size=1,\n        save_to_dir=augmented_dir,\n        save_prefix='brain_menin',\n        save_format='jpg'\n    ):\n        i += 1\n        if i >= target_count:\n            break\n    if i >= target_count:\n        break\n\nprint(f\"Augmented {i} images. Saved temporarily to: {augmented_dir}\")\n","metadata":{"executionInfo":{"elapsed":79094,"status":"ok","timestamp":1737833710170,"user":{"displayName":"Yoans Adel","userId":"04177296913070558532"},"user_tz":-120},"id":"pDM_IgybW2UY","outputId":"f53fd45c-5476-4356-e410-1e3133010ec9"},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#Combine augmented images and original images into single folder and add it to the dataset\ncombined_dir = '/content/GoogleDrive/MyDrive/Group3/final_data/brain_menin'\nos.makedirs(combined_dir, exist_ok=True)\n\ncopy_data(menin_dir, combined_dir)\ncopy_data(augmented_dir, combined_dir)\n","metadata":{"id":"idlLqNpe9lki","executionInfo":{"status":"ok","timestamp":1737862755264,"user_tz":-120,"elapsed":4275,"user":{"displayName":"Yoans Adel","userId":"04177296913070558532"}},"collapsed":true,"outputId":"1494cc38-9a3e-46af-9921-4ded207ef090","jupyter":{"outputs_hidden":true}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#Add brain glioma to the dataset\nsource_folder = '/content/GoogleDrive/MyDrive/Group3/output/brain_glioma'\ndestination_folder = '/content/GoogleDrive/MyDrive/Group3/final_data/brain_glioma'\n\ncopy_data(source_folder, destination_folder)","metadata":{"id":"P7OTl-u9BMZq","executionInfo":{"status":"ok","timestamp":1737862763871,"user_tz":-120,"elapsed":5334,"user":{"displayName":"Yoans Adel","userId":"04177296913070558532"}},"outputId":"1ca1b619-d14d-4ed8-94db-c1b76a7943de","collapsed":true,"jupyter":{"outputs_hidden":true}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#paths\nbrain_glioma = '/content/GoogleDrive/MyDrive/Group3/final_data/brain_glioma'\nbrain_menin = '/content/GoogleDrive/MyDrive/Group3/final_data/brain_menin'\n\nall_image_paths = []\nfor folder_path in [brain_glioma, brain_menin]:\n    for filename in os.listdir(folder_path):\n        if filename.endswith(('.png', '.jpg', '.jpeg')):  # if needed we will Adjust file extensions\n            all_image_paths.append(os.path.join(folder_path, filename))\nclasses, class_counts = extract_classes_and_counts(all_image_paths)\nprint(\"Classes:\", classes)\nprint(\"Class Counts:\", class_counts)","metadata":{"id":"DUd1RWw1IvR2","executionInfo":{"status":"ok","timestamp":1737836865463,"user_tz":-120,"elapsed":242,"user":{"displayName":"Yoans Adel","userId":"04177296913070558532"}},"outputId":"9d32d2c6-7d45-4687-e931-43d737699aaf"},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Splitting the data","metadata":{"id":"Hpky3tJ_Btzd"}},{"cell_type":"code","source":"input_folder = '/content/GoogleDrive/MyDrive/Group3/final_data'\noutput_folder = '/content/GoogleDrive/MyDrive/Group3/split_data'\n\nsplitfolders.ratio(input_folder, output=output_folder, seed=42, ratio=(.7, .1, .2))  # ratio of train, val, test","metadata":{"id":"6xjLpduR-j8-","executionInfo":{"status":"ok","timestamp":1737862740559,"user_tz":-120,"elapsed":49849,"user":{"displayName":"Yoans Adel","userId":"04177296913070558532"}},"outputId":"2c50449f-5a99-4de8-db92-5eaac9953697"},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Get a list of all subdirectories inside the input folder\n#subfolders = [os.path.join(input_folder, folder) for folder in os.listdir(input_folder) if os.path.isdir(os.path.join(input_folder, folder))]\n\n# Loop through each subfolder and split\n#for folder in subfolders:\n#    print(f\"Processing folder: {folder}\")\n#    splitfolders.ratio(input_folder, output=output_folder, seed=42, ratio=(.7, .1, .2))  # ratio of train, val, test\n","metadata":{"id":"xhtYThXl_O8T"},"outputs":[],"execution_count":null},{"cell_type":"code","source":"X_train = []\ny_train = []\nX_test = []\ny_test = []\nX_val = []\ny_val = []\nIMGSIZE = (128,128)\nimg_names = []\n\n\n#classes = sorted(os.listdir(os.path.join(output_folder, 'train')))\n#classes = ['brain_glioma', 'brain_menin']\n\n# Prepare image paths for processing\nfor root, dirs, files in os.walk(output_folder):\n    for file in files:\n        if file.endswith(('.png', '.jpg', '.jpeg')):\n            imgPath = os.path.join(root, file)\n            trainOrTestOrVal = imgPath.split('/')[-3]  # train/test/val\n            className = imgPath.split('/')[-2]  # the class\n\n            # Read and resize image\n            img = cv2.imread(imgPath)\n            img = cv2.resize(img,IMGSIZE)\n\n            # Append to appropriate dataset\n            if trainOrTestOrVal == 'train':\n                X_train.append(img)\n                y_train.append(classes.index(className))\n                img_names.append(file)\n            elif trainOrTestOrVal == 'test':\n                X_test.append(img)\n                y_test.append(classes.index(className))\n            elif trainOrTestOrVal == 'val':\n                X_val.append(img)\n                y_val.append(classes.index(className))\n\n# Print the number of images in each set\nprint(f\"Training set: {len(X_train)} images, {len(y_train)} labels\")\nprint(f\"Testing set: {len(X_test)} images, {len(y_test)} labels\")\nprint(f\"Validation set: {len(X_val)} images, {len(y_val)} labels\")","metadata":{"id":"Rrt4_XgyDFmx","executionInfo":{"status":"ok","timestamp":1737834599031,"user_tz":-120,"elapsed":11846,"user":{"displayName":"Yoans Adel","userId":"04177296913070558532"}},"outputId":"3f51229c-2c7d-43ab-d403-63f8cd93cd39"},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df = pd.DataFrame({\n    'File Name': img_names,\n    'Category': y_train\n})\nprint(df.head())\n","metadata":{"id":"eKDFTHcywCOl","executionInfo":{"status":"ok","timestamp":1737834637936,"user_tz":-120,"elapsed":260,"user":{"displayName":"Yoans Adel","userId":"04177296913070558532"}},"outputId":"6f295052-f683-4bd6-c9af-d505870ef20a"},"outputs":[],"execution_count":null},{"cell_type":"code","source":"X_train = np.array(X_train)\ny_train = np.array(y_train)\n\nX_test = np.array(X_test)\ny_test = np.array(y_test)","metadata":{"id":"kmrRS6hMrNIp","executionInfo":{"status":"ok","timestamp":1737834641768,"user_tz":-120,"elapsed":251,"user":{"displayName":"Yoans Adel","userId":"04177296913070558532"}}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Data Visualization","metadata":{"id":"vdDAkBcec1iv"}},{"cell_type":"code","source":"train_datagen = ImageDataGenerator(rescale=1./255,\n                                   shear_range=0.2,\n                                   zoom_range=0.2,\n                                   horizontal_flip=True)\n\ntrain_path = '/content/GoogleDrive/MyDrive/Group3/split_data/train'\ntrain_generator = train_datagen.flow_from_directory(\n    train_path,\n    target_size=(128, 128),\n    batch_size=32,\n    class_mode='categorical')","metadata":{"id":"bbiyLHj3Lkas","executionInfo":{"status":"ok","timestamp":1737837745125,"user_tz":-120,"elapsed":272,"user":{"displayName":"Yoans Adel","userId":"04177296913070558532"}},"outputId":"eb046be1-3704-45b0-fdd3-a7afe8766572"},"outputs":[],"execution_count":null},{"cell_type":"code","source":"show_images(train_generator, classes)","metadata":{"id":"FEGoG_PJL0Px","executionInfo":{"status":"ok","timestamp":1737837700760,"user_tz":-120,"elapsed":3205,"user":{"displayName":"Yoans Adel","userId":"04177296913070558532"}},"outputId":"66bdb25d-0602-4649-fd72-35207a285021"},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Converting to Tensor","metadata":{"id":"zMHQml9R6p-F"}},{"cell_type":"code","source":"x_train_tensor = torch.tensor(X_train, dtype=torch.float32).permute(0, 3, 1, 2)\nx_val_tensor = torch.tensor(X_val, dtype=torch.float32).permute(0, 3, 1, 2)\nx_test_tensor = torch.tensor(X_test, dtype=torch.float32).permute(0, 3, 1, 2)\n\ny_train_tensor = torch.tensor(y_train, dtype=torch.long)\ny_val_tensor = torch.tensor(y_val, dtype=torch.long)\ny_test_tensor = torch.tensor(y_test, dtype=torch.long)\n\n# Create TensorDatasets\ntrain_dataset = TensorDataset(x_train_tensor, y_train_tensor)\nval_dataset = TensorDataset(x_val_tensor, y_val_tensor)\ntest_dataset = TensorDataset(x_test_tensor, y_test_tensor)\n\n# Create DataLoaders\ntrain_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\nval_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)\ntest_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n","metadata":{"id":"ctH-4CVY6vlj","executionInfo":{"status":"ok","timestamp":1737838477844,"user_tz":-120,"elapsed":6334,"user":{"displayName":"Yoans Adel","userId":"04177296913070558532"}}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Model 1: ResNet\n","metadata":{"id":"giywpqTIdWMq"}},{"cell_type":"markdown","source":"## Build ResNet Model","metadata":{"id":"RRvdm8uMdrcO"}},{"cell_type":"code","source":"#INPUT_SHAPE = (3, 512, 512)\n#NUM_CLASSES = 2\n#BATCH_SIZE = 32\nLEARNING_RATE = 0.0001","metadata":{"id":"VU8fYhmGAl5s","executionInfo":{"status":"ok","timestamp":1737858736394,"user_tz":-120,"elapsed":256,"user":{"displayName":"Yoans Adel","userId":"04177296913070558532"}}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"base_model = models.resnet50(pretrained=True)\nbase_model.fc = nn.Linear(base_model.fc.in_features, 2)","metadata":{"id":"t1otSMfcAlmV","executionInfo":{"status":"ok","timestamp":1737838757711,"user_tz":-120,"elapsed":2289,"user":{"displayName":"Yoans Adel","userId":"04177296913070558532"}},"outputId":"fdd924f4-3608-48d0-d55d-6e2bbdffa070"},"outputs":[],"execution_count":null},{"cell_type":"code","source":"device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nresnet_model = base_model.to(device)\n\ncriterion = nn.CrossEntropyLoss()\noptimizer = optim.Adam(resnet_model.fc.parameters(), lr=LEARNING_RATE)","metadata":{"id":"9gCW-8-uAleY","executionInfo":{"status":"ok","timestamp":1737858740604,"user_tz":-120,"elapsed":235,"user":{"displayName":"Yoans Adel","userId":"04177296913070558532"}}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Train and save ResNet Model","metadata":{"id":"F2dmCIuzKFUe"}},{"cell_type":"code","source":"train_losses = []\ntrain_accuracies = []\nval_losses = []\nval_accuracies = []\n\nnum_epochs = 50","metadata":{"id":"bDK9Uw9oeR7M","executionInfo":{"status":"ok","timestamp":1737859108305,"user_tz":-120,"elapsed":296,"user":{"displayName":"Yoans Adel","userId":"04177296913070558532"}}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"for epoch in range(num_epochs):\n    train_loss, train_accuracy = train_epoch(resnet_model, train_loader, criterion, optimizer, device)\n    val_loss, val_accuracy = validate_epoch(resnet_model, val_loader, criterion, device)\n\n    train_losses.append(train_loss)\n    train_accuracies.append(train_accuracy)\n    val_losses.append(val_loss)\n    val_accuracies.append(val_accuracy)\n\n    print(f\"Epoch {epoch+1}/{num_epochs}, \"\n          f\"Train Loss: {train_loss:.4f}, Train Accuracy: {train_accuracy:.2f}%, \"\n          f\"Validation Loss: {val_loss:.4f}, Validation Accuracy: {val_accuracy:.2f}%\")","metadata":{"collapsed":true,"id":"g8sV2NbMksMx","executionInfo":{"status":"ok","timestamp":1737857324240,"user_tz":-120,"elapsed":18553369,"user":{"displayName":"Yoans Adel","userId":"04177296913070558532"}},"outputId":"6bab22a1-145e-4df2-a483-283d35e540e8","jupyter":{"outputs_hidden":true}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"plot_training_history(train_losses, val_losses, train_accuracies, val_accuracies)","metadata":{"id":"6HofA55In1ep","executionInfo":{"status":"ok","timestamp":1737857347286,"user_tz":-120,"elapsed":833,"user":{"displayName":"Yoans Adel","userId":"04177296913070558532"}},"outputId":"b4ab0d0a-1830-4623-899d-fbbc12909277"},"outputs":[],"execution_count":null},{"cell_type":"code","source":"os.makedirs('/content/GoogleDrive/MyDrive/Group3/models', exist_ok=True)\ntorch.save(resnet_model.state_dict(), '/content/GoogleDrive/MyDrive/Group3/models/resnet_model.pth')","metadata":{"id":"tUURx1jt4MjQ","executionInfo":{"status":"ok","timestamp":1737857463848,"user_tz":-120,"elapsed":523,"user":{"displayName":"Yoans Adel","userId":"04177296913070558532"}}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Model 2: MobileNet\n","metadata":{"id":"NPSDrbKEBUNc"}},{"cell_type":"markdown","source":"## Build MobileNet Model","metadata":{"id":"mbqQLlHJektP"}},{"cell_type":"code","source":"mobilenet_model = models.mobilenet_v2(pretrained=True)\nmobilenet_model.classifier[1] = nn.Linear(mobilenet_model.last_channel, 2)","metadata":{"id":"S9AdNM0Cf0mQ","executionInfo":{"status":"ok","timestamp":1737863037316,"user_tz":-120,"elapsed":269,"user":{"displayName":"Yoans Adel","userId":"04177296913070558532"}}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nmobilenet_model = mobilenet_model.to(device)\ncriterion = nn.CrossEntropyLoss()\noptimizer = optim.Adam(mobilenet_model.parameters(), lr=0.0001)","metadata":{"id":"K2JSmbXi75ZE","executionInfo":{"status":"ok","timestamp":1737858852136,"user_tz":-120,"elapsed":283,"user":{"displayName":"Yoans Adel","userId":"04177296913070558532"}}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"summary(mobilenet_model, input_size=(3, 512, 512))","metadata":{"id":"vm17X5nc7-hE","executionInfo":{"status":"ok","timestamp":1737860189659,"user_tz":-120,"elapsed":1107,"user":{"displayName":"Yoans Adel","userId":"04177296913070558532"}},"outputId":"58b59b5b-ba8a-4770-a947-751b0372ec19","collapsed":true,"jupyter":{"outputs_hidden":true}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Train and save MobileNet Model","metadata":{"id":"H7hRZwRIektP"}},{"cell_type":"code","source":"mobile_train_losses = []\nmobile_val_losses = []\nmobile_train_accuracies = []\nmobile_val_accuracies = []","metadata":{"id":"hLvV4YiGfzOV","executionInfo":{"status":"ok","timestamp":1737860253433,"user_tz":-120,"elapsed":267,"user":{"displayName":"Yoans Adel","userId":"04177296913070558532"}}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"num_epochs = 50\nbest_val_loss = float('inf')\npatience = 3  #Stop if there is no sign of improvements for 3 epochs\nepochs_without_improvement = 0","metadata":{"id":"5j8Yqbgzjju2","executionInfo":{"status":"ok","timestamp":1737860504961,"user_tz":-120,"elapsed":268,"user":{"displayName":"Yoans Adel","userId":"04177296913070558532"}}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"for epoch in range(num_epochs):\n\n    train_loss, train_accuracy = train_epoch(mobilenet_model, train_loader, criterion, optimizer, device)\n    val_loss, val_accuracy = validate_epoch(mobilenet_model, val_loader, criterion, device)\n\n    mobile_train_losses.append(train_loss)\n    mobile_train_accuracies.append(train_accuracy)\n    mobile_val_losses.append(val_loss)\n    mobile_val_accuracies.append(val_accuracy)\n\n    print(f\"Epoch {epoch+1}/{num_epochs}, \"\n          f\"Train Loss: {train_loss:.4f}, Train Accuracy: {train_accuracy:.2f}%, \"\n          f\"Validation Loss: {val_loss:.4f}, Validation Accuracy: {val_accuracy:.2f}%\")\n    if val_loss < best_val_loss:\n        best_val_loss = val_loss\n        epochs_without_improvement = 0\n    else:\n        epochs_without_improvement += 1\n\n    if epochs_without_improvement >= patience:\n        print(f\"Early stopping at epoch {epoch+1}\")\n        break\n","metadata":{"collapsed":true,"id":"HI4r9yE2reeg","executionInfo":{"status":"ok","timestamp":1737861253692,"user_tz":-120,"elapsed":641122,"user":{"displayName":"Yoans Adel","userId":"04177296913070558532"}},"outputId":"ae82b9ed-ef8b-4177-b340-47af56b0149a","jupyter":{"outputs_hidden":true}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"plot_training_history(mobile_train_losses, mobile_val_losses, mobile_train_accuracies, mobile_val_accuracies)","metadata":{"id":"s5EuT29mskbj","executionInfo":{"status":"ok","timestamp":1737861332205,"user_tz":-120,"elapsed":881,"user":{"displayName":"Yoans Adel","userId":"04177296913070558532"}},"outputId":"cfa1f737-db53-4cda-ea2e-db7c93b2085f"},"outputs":[],"execution_count":null},{"cell_type":"code","source":"torch.save(mobilenet_model.state_dict(), '/content/GoogleDrive/MyDrive/Group3/models/mobilenet_model.pth')","metadata":{"id":"ujquRutP4UY0","executionInfo":{"status":"ok","timestamp":1737861338971,"user_tz":-120,"elapsed":251,"user":{"displayName":"Yoans Adel","userId":"04177296913070558532"}}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Evaluation and Results","metadata":{"id":"FgvcwUMpe4Vz"}},{"cell_type":"markdown","source":"## Import and Load Models","metadata":{"id":"DpLToLiDuDQM"}},{"cell_type":"code","source":"from google.colab import drive\ndrive.mount('/content/GoogleDrive')","metadata":{"id":"n6Ev_lh6t3GT","executionInfo":{"status":"ok","timestamp":1737863183974,"user_tz":-120,"elapsed":1944,"user":{"displayName":"Yoans Adel","userId":"04177296913070558532"}},"outputId":"6f05f0ff-a140-432b-ef05-93b722b74f19"},"outputs":[],"execution_count":null},{"cell_type":"code","source":"   #Create the ResNet model instance with\n   base_model = models.resnet50(pretrained=True)\n   base_model.fc = nn.Linear(base_model.fc.in_features, 2)\n   resnet_model = base_model.to(device)  #Move to device (GPU or CPU)\n\n   #Create the MobileNet model instance\n   mobilenet_model = models.mobilenet_v2(pretrained=True)\n   mobilenet_model.classifier[1] = nn.Linear(mobilenet_model.last_channel, 2)\n   mobilenet_model = mobilenet_model.to(device) # Move to device (GPU or CPU)","metadata":{"id":"cSI_VMId4pnC","executionInfo":{"status":"ok","timestamp":1737863264251,"user_tz":-120,"elapsed":1052,"user":{"displayName":"Yoans Adel","userId":"04177296913070558532"}}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#Load resnet_model\nresnet_model.load_state_dict(torch.load('/content/GoogleDrive/MyDrive/Group3/models/resnet_model.pth'))\n#Load mobilenet_model\nmobilenet_model.load_state_dict(torch.load('/content/GoogleDrive/MyDrive/Group3/models/mobilenet_model.pth'))","metadata":{"id":"1p9CGuWZ5IwN","executionInfo":{"status":"ok","timestamp":1737863309313,"user_tz":-120,"elapsed":488,"user":{"displayName":"Yoans Adel","userId":"04177296913070558532"}},"outputId":"9408b451-baa1-4bc8-9620-768c28e27b6c"},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#Evaluation mode\nresnet_model.eval()\nmobilenet_model.eval()","metadata":{"collapsed":true,"id":"hl-APMP75ZI2","executionInfo":{"status":"ok","timestamp":1737863323556,"user_tz":-120,"elapsed":286,"user":{"displayName":"Yoans Adel","userId":"04177296913070558532"}},"outputId":"b6bd0fec-df82-4249-c4f7-ec0b89b6bd6c","jupyter":{"outputs_hidden":true}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Evaluating MobileNet and ResNet\n","metadata":{"id":"ujpducDXeI3d"}},{"cell_type":"code","source":"#Predictions for ResNet\nresnet_predictions = []\nwith torch.no_grad():\n    for inputs, labels in test_loader:\n        inputs, labels = inputs.to(device), labels.to(device)\n        outputs = resnet_model(inputs)\n        _, preds = torch.max(outputs, 1)\n        resnet_predictions.extend(preds.cpu().numpy())\n\n#Predictions for MobileNet\nmobilenet_predictions = []\nwith torch.no_grad():\n    for inputs, labels in test_loader:\n        inputs, labels = inputs.to(device), labels.to(device)\n        outputs = mobilenet_model(inputs)\n        _, preds = torch.max(outputs, 1)\n        mobilenet_predictions.extend(preds.cpu().numpy())\n\n","metadata":{"id":"BXHW9DLwfuO8","executionInfo":{"status":"ok","timestamp":1737861522812,"user_tz":-120,"elapsed":33057,"user":{"displayName":"Yoans Adel","userId":"04177296913070558532"}}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#Convert predictions and true labels (to be array) for evaluation\nresnet_predictions = np.array(resnet_predictions)\nmobilenet_predictions = np.array(mobilenet_predictions)\ny_test_np = y_test\n\n#Calculate evaluation metrics for ResNet\nresnet_accuracy = accuracy_score(y_test_np, resnet_predictions)\nresnet_precision = precision_score(y_test_np, resnet_predictions)\nresnet_recall = recall_score(y_test_np, resnet_predictions)\nresnet_f1 = f1_score(y_test_np, resnet_predictions)\n\n#Calculate evaluation metrics for MobileNet\nmobilenet_accuracy = accuracy_score(y_test_np, mobilenet_predictions)\nmobilenet_precision = precision_score(y_test_np, mobilenet_predictions)\nmobilenet_recall = recall_score(y_test_np, mobilenet_predictions)\nmobilenet_f1 = f1_score(y_test_np, mobilenet_predictions)","metadata":{"id":"iOQA8WMT7zGT","executionInfo":{"status":"ok","timestamp":1737863358401,"user_tz":-120,"elapsed":269,"user":{"displayName":"Yoans Adel","userId":"04177296913070558532"}}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#Dictionary of metrics\nmetrics = {\n    'Model': ['ResNet', 'MobileNet'],\n    'Accuracy': [resnet_accuracy, mobilenet_accuracy],\n    'Precision': [resnet_precision, mobilenet_precision],\n    'Recall': [resnet_recall, mobilenet_recall],\n    'F1-score': [resnet_f1, mobilenet_f1]\n}\n\ndf_metrics = pd.DataFrame(metrics)\nprint(df_metrics)","metadata":{"id":"0x54pzvYftyH","executionInfo":{"status":"ok","timestamp":1737863456020,"user_tz":-120,"elapsed":282,"user":{"displayName":"Yoans Adel","userId":"04177296913070558532"}},"outputId":"6e746a94-dcaa-48eb-ac4b-d003bcecde22"},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Visualization","metadata":{"id":"tX2h6lbCfagx"}},{"cell_type":"code","source":"#comparing Using bar chart\nmodels = ['ResNet', 'MobileNet']\naccuracy = [resnet_accuracy, mobilenet_accuracy]\nprecision = [resnet_precision, mobilenet_precision]\nrecall = [resnet_recall, mobilenet_recall]\nf1_score = [resnet_f1, mobilenet_f1]\n\nx = np.arange(len(models))\nwidth = 0.2\n\nfig, ax = plt.subplots()\nrects1 = ax.bar(x - width*1.5, accuracy, width, label='Accuracy')\nrects2 = ax.bar(x - width/2, precision, width, label='Precision')\nrects3 = ax.bar(x + width/2, recall, width, label='Recall')\nrects4 = ax.bar(x + width*1.5, f1_score, width, label='F1-score')\n\nax.set_ylabel('Scores')\nax.set_title('Model Performance Comparison')\nax.set_xticks(x)\nax.set_xticklabels(models)\nax.legend()\n\nfig.tight_layout()\nplt.show()","metadata":{"id":"69kUYUFvBwxZ","executionInfo":{"status":"ok","timestamp":1737861640753,"user_tz":-120,"elapsed":348,"user":{"displayName":"Yoans Adel","userId":"04177296913070558532"}},"outputId":"af1f93b4-eab9-4216-9ca2-fea7f718de73"},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#Create confusion matrix for ResNet\nplot_confusion_matrix(y_test, resnet_predictions, classes)","metadata":{"id":"fEwN9_iMAqtR","executionInfo":{"status":"ok","timestamp":1737862488936,"user_tz":-120,"elapsed":304,"user":{"displayName":"Yoans Adel","userId":"04177296913070558532"}},"outputId":"a23a0e67-c57a-4290-8f44-16d26306ff61"},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#Create confusion matrix for MobileNet\nplot_confusion_matrix(y_test, mobilenet_predictions, classes)","metadata":{"id":"KddxuoMPrTg5","executionInfo":{"status":"ok","timestamp":1737862498861,"user_tz":-120,"elapsed":264,"user":{"displayName":"Yoans Adel","userId":"04177296913070558532"}},"outputId":"37b30577-ad02-4b5f-d97b-37942b10b19e"},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#Display images with ResNet predictions\nshow_images_with_predictions(X_test, y_test, resnet_predictions, classes, num_images=25)","metadata":{"id":"x1_04qyc8xc3","executionInfo":{"status":"ok","timestamp":1737861907093,"user_tz":-120,"elapsed":2928,"user":{"displayName":"Yoans Adel","userId":"04177296913070558532"}},"outputId":"4576c0b9-f25c-43e2-d2e3-14e8ab583f7d"},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#Display images with MobileNet predictions\nshow_images_with_predictions(X_test, y_test, mobilenet_predictions, classes, num_images=25)","metadata":{"id":"DWrdf3x3okc9","executionInfo":{"status":"ok","timestamp":1737861812886,"user_tz":-120,"elapsed":3150,"user":{"displayName":"Yoans Adel","userId":"04177296913070558532"}},"outputId":"c3d47c1a-eb5b-40e0-9c9d-7876dbead8ae"},"outputs":[],"execution_count":null}]}